{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3.3 PCA and Linear Regression (4 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Principal Component Regression (PCR) is a method used in statistical analysis, similar to traditional linear regression, model the relationship between a target and the predictor variables.\n",
    "\n",
    "PCR differs from standard linear regression in that it uses principal components as the predictors rather than the original variables.\n",
    "\n",
    "PCR's process involves:\n",
    "<ol>\n",
    "<li>Implementing Principal Component Analysis (PCA) to transform predictor variables into principal components. Selecting the top k principal components, which account for the majority of the data variance (where k is less than number of original variables). The choice of k is based on cross-validation results. </li>\n",
    "\n",
    "<li>Constructing a linear regression model using these k principal components.</li>\n",
    "\n",
    "<li>The reasoning behind PCR is that these fewer principal components capture the majority of the data's variability, and are assumed to be more representative of the connection with the dependent variable. Hence, PCR focuses on a smaller, more significant subset of principal components rather than utilizing all original variables for regression analysis.</li>\n",
    "</ol>\n",
    "\n",
    "Write your code in the respective cells. Of course, you can add additional cells or change their order, but please don't significantly change the structure of the notebook. You must use PyTorch tensors to perform all the calculations.  \n",
    "For each question that requires written answer, please write it in a markdown cell."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Getting the data ready"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "this version of pandas is incompatible with numpy < 1.20.3\nyour numpy version is 1.20.2.\nPlease upgrade numpy to >= 1.20.3 to use this pandas version",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Camilo Martínez\\OneDrive - Universität des Saarlandes\\Semestern\\1. Semester\\Neural Networks Theory and Implementation\\nnti\\Assignment_3\\code\\NNTI_assignment_3.ipynb Cell 4\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Camilo%20Mart%C3%ADnez/OneDrive%20-%20Universit%C3%A4t%20des%20Saarlandes/Semestern/1.%20Semester/Neural%20Networks%20Theory%20and%20Implementation/nnti/Assignment_3/code/NNTI_assignment_3.ipynb#W3sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpandas\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mpd\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Camilo%20Mart%C3%ADnez/OneDrive%20-%20Universit%C3%A4t%20des%20Saarlandes/Semestern/1.%20Semester/Neural%20Networks%20Theory%20and%20Implementation/nnti/Assignment_3/code/NNTI_assignment_3.ipynb#W3sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpreprocessing\u001b[39;00m \u001b[39mimport\u001b[39;00m scale \n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Camilo%20Mart%C3%ADnez/OneDrive%20-%20Universit%C3%A4t%20des%20Saarlandes/Semestern/1.%20Semester/Neural%20Networks%20Theory%20and%20Implementation/nnti/Assignment_3/code/NNTI_assignment_3.ipynb#W3sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodel_selection\u001b[39;00m \u001b[39mimport\u001b[39;00m train_test_split\n",
      "File \u001b[1;32mc:\\Anaconda\\lib\\site-packages\\pandas\\__init__.py:22\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[39mdel\u001b[39;00m _hard_dependencies, _dependency, _missing_dependencies\n\u001b[0;32m     21\u001b[0m \u001b[39m# numpy compat\u001b[39;00m\n\u001b[1;32m---> 22\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpandas\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcompat\u001b[39;00m \u001b[39mimport\u001b[39;00m is_numpy_dev \u001b[39mas\u001b[39;00m _is_numpy_dev  \u001b[39m# pyright: ignore # noqa:F401\u001b[39;00m\n\u001b[0;32m     24\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     25\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39mpandas\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_libs\u001b[39;00m \u001b[39mimport\u001b[39;00m hashtable \u001b[39mas\u001b[39;00m _hashtable, lib \u001b[39mas\u001b[39;00m _lib, tslib \u001b[39mas\u001b[39;00m _tslib\n",
      "File \u001b[1;32mc:\\Anaconda\\lib\\site-packages\\pandas\\compat\\__init__.py:18\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtyping\u001b[39;00m \u001b[39mimport\u001b[39;00m TYPE_CHECKING\n\u001b[0;32m     17\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpandas\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_typing\u001b[39;00m \u001b[39mimport\u001b[39;00m F\n\u001b[1;32m---> 18\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpandas\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcompat\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mnumpy\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[0;32m     19\u001b[0m     is_numpy_dev,\n\u001b[0;32m     20\u001b[0m     np_version_under1p21,\n\u001b[0;32m     21\u001b[0m )\n\u001b[0;32m     22\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpandas\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcompat\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpyarrow\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[0;32m     23\u001b[0m     pa_version_under1p01,\n\u001b[0;32m     24\u001b[0m     pa_version_under2p0,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     31\u001b[0m     pa_version_under9p0,\n\u001b[0;32m     32\u001b[0m )\n\u001b[0;32m     34\u001b[0m \u001b[39mif\u001b[39;00m TYPE_CHECKING:\n",
      "File \u001b[1;32mc:\\Anaconda\\lib\\site-packages\\pandas\\compat\\numpy\\__init__.py:22\u001b[0m\n\u001b[0;32m     18\u001b[0m     np_percentile_argname \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39minterpolation\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m     21\u001b[0m \u001b[39mif\u001b[39;00m _nlv \u001b[39m<\u001b[39m Version(_min_numpy_ver):\n\u001b[1;32m---> 22\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mImportError\u001b[39;00m(\n\u001b[0;32m     23\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mthis version of pandas is incompatible with numpy < \u001b[39m\u001b[39m{\u001b[39;00m_min_numpy_ver\u001b[39m}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m     24\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39myour numpy version is \u001b[39m\u001b[39m{\u001b[39;00m_np_version\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m     25\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mPlease upgrade numpy to >= \u001b[39m\u001b[39m{\u001b[39;00m_min_numpy_ver\u001b[39m}\u001b[39;00m\u001b[39m to use this pandas version\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m     26\u001b[0m     )\n\u001b[0;32m     29\u001b[0m __all__ \u001b[39m=\u001b[39m [\n\u001b[0;32m     30\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mnp\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m     31\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m_np_version\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m     32\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mis_numpy_dev\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m     33\u001b[0m ]\n",
      "\u001b[1;31mImportError\u001b[0m: this version of pandas is incompatible with numpy < 1.20.3\nyour numpy version is 1.20.2.\nPlease upgrade numpy to >= 1.20.3 to use this pandas version"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import scale \n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x0</th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "      <th>x5</th>\n",
       "      <th>x6</th>\n",
       "      <th>x7</th>\n",
       "      <th>x8</th>\n",
       "      <th>x9</th>\n",
       "      <th>x10</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.098</td>\n",
       "      <td>25.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.9968</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.68</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.092</td>\n",
       "      <td>15.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.9970</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.65</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.2</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.075</td>\n",
       "      <td>17.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.9980</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.58</td>\n",
       "      <td>9.8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     x0    x1    x2   x3     x4    x5    x6      x7    x8    x9  x10  y\n",
       "0   7.4  0.70  0.00  1.9  0.076  11.0  34.0  0.9978  3.51  0.56  9.4  5\n",
       "1   7.8  0.88  0.00  2.6  0.098  25.0  67.0  0.9968  3.20  0.68  9.8  5\n",
       "2   7.8  0.76  0.04  2.3  0.092  15.0  54.0  0.9970  3.26  0.65  9.8  5\n",
       "3  11.2  0.28  0.56  1.9  0.075  17.0  60.0  0.9980  3.16  0.58  9.8  6\n",
       "4   7.4  0.70  0.00  1.9  0.076  11.0  34.0  0.9978  3.51  0.56  9.4  5"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./data.csv', sep=',')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1599, 11) (1599,)\n"
     ]
    }
   ],
   "source": [
    "X = df.values[:,:-1]\n",
    "y = df.values[:,-1]\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1279, 11)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Standardize Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled, X_test_scaled = scale(X_train), scale(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3.1 Perform PCA on the input data and visualize the data (2 point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled_tensor = torch.tensor(X_train_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate covariance matrix of the input data. Hint: You can use torch.matmul for matrix multiplication."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform eigendecomposion of the covariance matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract the first two principal components of the data, i.e. reduce the dimensionality of the dataset to 2. Plot the result. Different numbers must be represented as different colors on the scatter plot. You can use a randomly sampled portion of the data so that the plot doesn't get cluttered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the graph of cumulative explained variance vs number of components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3.2 Train Regression models (2 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given training dataset $D = \\{x_i,y_i\\}_{i=1}^n$ where $x_i \\in \\mathbb{R}^d, y_i \\in \\mathbb{R}$ the ordinary linear least square regression minimizes the cost function \n",
    "$f(x,y;w) = \\frac{1}{n} \\sum_{i=1}^n (y_i - \\langle w, x_i \\rangle - b )^2$  \n",
    "But sometimes this leads to overfitting or ill posed problems hence we add a regularizational term to the objective function  \n",
    "$f(x,y;w) = \\frac{1}{n} \\sum_{i=1}^n (y_i - \\langle w, x_i \\rangle - b )^2 + \\lambda \\sum_{i=1}^d w_i^2$  \n",
    "In practice we artificially add another dimension of 1's to $X$ to absorb the offset term b such that the objective function in matrix vector form becomes  \n",
    "$f(x,y;w) = \\frac{1}{n} \\Vert Y - Xw \\Vert^2 + \\lambda \\Vert w \\Vert^2 $ where\n",
    "    $\n",
    "        X = \\begin{bmatrix}\n",
    "    X_{1,1} & \\cdots & X_{1,d} & 1\\\\\n",
    "    X_{2,1}  & \\cdots & X_{2,d} & 1 \\\\\n",
    "    \\vdots & \\vdots & \\vdots & \\vdots \\\\\n",
    "    X_{n,1} & \\cdots & X_{n,d} & 1\n",
    "    \\end{bmatrix}\n",
    "    $\n",
    " and $w = \\begin{bmatrix}w_1 & w_2 & ... & w_d & b \\end{bmatrix}^T$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The closed form of $w^*$ which minimizes objective function $f(x,y;w) = \\frac{1}{n} \\Vert Y - Xw \\Vert^2 + \\lambda \\Vert w \\Vert^2 $ is $w^* = (X^TX + \\lambda \\mathbb{I})^{-1}X^TY$ . Your task is to programatically implement this closed form solution for ridge regression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.2a (1 point)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement the fit() function in the ridge_regression class which takes three parameters X, Y and LAMBDA. The fit() function computes the minimizer $w^*$ for the regularized mean squared error objective function. Store the value of $w^*$ in self.w  \n",
    "\n",
    "Implement the predict() function that takes a matrix X and returns the predictions of the model on X and since the bias term is absorbed in $w$, please do not forget to add another dimension of 1's to X as described earlier in both the fit() and predict functions\n",
    "\n",
    "Assume that fit() is called before using predict(). \n",
    "**Use only basic matrix vector operations from numpy**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ridge_regression:\n",
    "    def __init__(self):\n",
    "        self.w = None # self.w.shape = (d+1,)\n",
    "    \n",
    "    def fit(self, X, Y, LAMBDA = 0.3): \n",
    "        \"\"\"\n",
    "        args: X.shape = (n, d). We account for the bias parameter w_0 in the \n",
    "                design matrix X by artificially adding another dimension\n",
    "                Y.shape = (n, 1)\n",
    "        returns: None\n",
    "        Note that you have to artificially add a dimension of 1 as defined earlier to account for the bias term\n",
    "        \"\"\"\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Note that you have to artificially add a dimension of 1 as defined earlier to account for the bias term\n",
    "        \"\"\"\n",
    "        raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.3.2b Run Baseline Regression Model (0.5 points)\n",
    "\n",
    "To evaluate the performance of the PCR model, we need to have benchmark to compare with. For this train a regression model using the original variables as the Input.\n",
    "\n",
    "Record the mean squared error for the evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.3.2c Classification using principal components (0.5 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For $K = 1...11$ select top K principal components. Project the X_train_scaled data into a subspace using these $K$ princiapl components. Train a Regression model using this projected dataset. Repeat the projection operation on the X_test_scaled data and predict the output. Evaluate the model's performance using mean squared error.\n",
    "\n",
    "Plot a graph of model's performance against its $K$ value. Also Plot the baseline MSE from the previous question in the same graph for comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How does the performance change with the different $K$ values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
